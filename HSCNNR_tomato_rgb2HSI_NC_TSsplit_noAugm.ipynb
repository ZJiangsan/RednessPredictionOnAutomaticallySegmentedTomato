{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HSCNNR_tomato_rgb2HSI_NC_TSsplit_noAugm.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"oFWHFnJO4i3o","colab_type":"code","colab":{}},"source":["!pip install --no-cache-dir -I pillow\n","!pip install hdf5storage\n","!pip install http://download.pytorch.org/whl/cu92/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n","!pip3 install torchvision\n","#!git clone https://github.com/lanpa/tensorboardX && cd tensorboardX && python setup.py install\n","!pip install tensorboardX\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SuO41DNu4dBG","colab_type":"code","outputId":"faadf3c6-6b3e-40f5-c3c0-2a3f8b7c716c","executionInfo":{"status":"ok","timestamp":1573853504241,"user_tz":-60,"elapsed":36168,"user":{"displayName":"jiangsan Zhao","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAoBwUnVvBMKk1dtsJwtnDFO6TQWaqdp4PFTMYbs74=s64","userId":"12734603351330672425"}},"colab":{"base_uri":"https://localhost:8080/","height":120}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/My Drive/app/folder_name/\") # folder containing your images used for training and testing \n","path=os.getcwd() "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"duKaP9IE4i6_","colab_type":"code","colab":{}},"source":["### \n","from __future__ import division\n","from scipy import interpolate\n","import random\n","import os\n","import os.path\n","import h5py\n","import cv2\n","import glob\n","import numpy as np\n","\n","import PIL\n","\n","import scipy.io\n","import matplotlib\n","matplotlib.use('Agg')\n","from matplotlib.backends.backend_agg import FigureCanvasAgg\n","from matplotlib.figure import Figure\n","\n","import torchvision.utils as utils\n","from tensorboardX import SummaryWriter\n","###\n","import torch\n","import torch.nn as nn\n","import argparse\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","import torch.utils.data as udata\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision.utils as utils\n","import time\n","import scipy.io as sio\n","import logging\n","import hdf5storage\n","import datetime\n","from math import sqrt\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCJLUwq_bfcv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"URifxhttG76U","colab_type":"code","colab":{}},"source":["\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","def save_checkpoint_sp(model_path, epoch, iteration, model, optimizer, evaluation):\n","    \"\"\"Save the checkpoint.\"\"\"\n","    state = {\n","            'epoch': epoch,\n","            'iter': iteration,\n","            'state_dict': model.state_dict(),\n","            'optimizer' : optimizer.state_dict(),\n","            }\n","    \n","    torch.save(state, os.path.join(model_path, 'hscnn_6layer_dim10_{}.pkl'.format(evaluation)))\n","\n","def plot_spectrum(real, fake, epoch, i):\n","    x =np.linspace(397.32, 1003.58, 204, endpoint=True) # the wavebands of the hyperspectral image\n","    fig = Figure()\n","    canvas = FigureCanvasAgg(fig)\n","    ax = fig.gca()\n","    plot_real,  = ax.plot(x, real)\n","    plot_fake,  = ax.plot(x, fake)\n","    fig.legend((plot_real,plot_fake), ('real', 'fake'))\n","    canvas.draw()\n","    fig.savefig(os.path.join(iteration_path, \"{}_test_{}.png\".format(epoch,i)))\n","    I = np.fromstring(canvas.tostring_rgb(), dtype='uint8', sep='')\n","    I = I.reshape(canvas.get_width_height()[::-1]+(3,))\n","    I = np.transpose(I, [2,0,1])\n","    return np.float32(I)\n","\n","def initialize_logger(file_dir):\n","    \"\"\"Print the results in the log file.\"\"\"\n","    logger = logging.getLogger()\n","    fhandler = logging.FileHandler(filename=file_dir, mode='a')\n","    formatter = logging.Formatter('%(asctime)s - %(message)s',\"%Y-%m-%d %H:%M:%S\")\n","    fhandler.setFormatter(formatter)\n","    logger.addHandler(fhandler)\n","    logger.setLevel(logging.INFO)\n","    return logger\n","\n","def save_matv73(mat_name, var_name, var):\n","    hdf5storage.savemat(mat_name, {var_name: var}, format='7.3', store_python_metadata=True)\n","\n","    \n","def get_reconstruction(input, num_split, dimension, model):\n","    \"\"\"As the limited GPU memory split the input.\"\"\"\n","    input_split = torch.split(input,  int(input.shape[3]/num_split), dim=dimension)\n","    output_split = []\n","    for i in range(num_split):\n","        var_input = Variable(input_split[i].cuda())\n","        var_output = model(var_input)\n","        output_split.append(var_output.data)\n","        if i == 0:\n","            output = output_split[i]\n","        else:\n","            output = torch.cat((output, output_split[i]), dim=dimension)\n","    \n","    return output\n","\n","\n","def reconstruction(rgb,model):\n","    \"\"\"Output the final reconstructed hyperspectral images.\"\"\"\n","    img_res = get_reconstruction(torch.from_numpy(rgb).float(),1, 3, model)\n","    img_res = img_res.cpu().numpy()*1\n","    img_res = np.transpose(np.squeeze(img_res))\n","    img_res_limits = np.minimum(img_res,1)\n","    img_res_limits = np.maximum(img_res_limits,0)\n","    return img_res_limits\n","\n","def mrae_loss(im_true, im_fake):\n","    error = torch.abs(im_fake-im_true)/im_true\n","    rrmse = torch.mean(error.view(-1))\n","    return rrmse\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_FSOuEvKG734","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQ57uoaM503I","colab_type":"code","colab":{}},"source":["## new fucntion for process data\n","path=os.getcwd() \n","\n","def normalize(data):\n","    return data/np.amax(data)\n","\n","\n","def data_process(path=path):\n","    NO. = 1\n","    h5f = h5py.File('train_tomato.h5', 'w')  ## the file concatenated hsi and rgb in one file\n","    filenames_hyper = glob.glob(os.path.join(path,'tomato_hsi','*.h5'))\n","    filenames_rgb = glob.glob(os.path.join(path,'tomato_hsi','*.png'))\n","    filenames_hyper.sort()\n","    filenames_rgb.sort()\n","    for i in range(len(filenames_hyper)):\n","        print(\"\\n\")\n","        print(filenames_hyper[i], filenames_rgb[i])\n","        # load hyperspectral image\n","        mat =  h5py.File(filenames_hyper[i],'r')\n","        hyper = np.float32(np.array(mat['img']))\n","#            hyper.shape\n","        hyper = np.transpose(hyper, [0,2,1])\n","        hyper = normalize(hyper)\n","        print(\"hyper_test_max\", np.amax(hyper))\n","        print(\"hyper_test_min\",np.amin(hyper))\n","        mat.close()\n","        # load rgb image\n","        rgb =  cv2.imread(filenames_rgb[i])\n","        rgb=cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n","        \n","        rgb = np.transpose(rgb, [2,0,1])\n","\n","        rgb = normalize(np.float32(rgb))\n","        print(\"rgb_test_max\", np.amax(np.float32(rgb)))\n","        print(\"rgb_test_min\", np.amin(np.float32(rgb)))\n","#            mat.close()\n","            # creat patches\n","        data = np.concatenate((hyper,rgb), 0)\n","        h5f.create_dataset(str(NO.), data=data)\n","        NO. += 1\n","    h5f.close()\n","    print(\"NO. of samples: {}\".format(NO.-1))\n","\n","class HyperDataset(udata.Dataset):\n","    def __init__(self, crop_size=64):\n","        self.crop_size = crop_size\n","        h5f = h5py.File('train_tomato.h5', 'r')\n","        self.keys = list(h5f.keys())\n","        keys.sort()\n","        h5f.close()\n","    def __len__(self):\n","        return len(self.keys)\n","    def __getitem__(self, index):\n","        h5f = h5py.File('train_tomato.h5', 'r')\n","\n","        key = str(self.keys[index])\n","        data = np.array(h5f[key])\n","        data = torch.Tensor(data)\n","        # crop\n","        w = int(data.size()[1])\n","        h = int(data.size()[2])\n","        th, tw = self.crop_size, self.crop_size\n","        if w > tw or h > th:\n","                i = 0\n","                j = 0\n","            data = data[:,i:i+th,j:j+tw]\n","        h5f.close()\n","        return data[0:204,:,:], data[204:207,:,:]\n","\n","def batch_MRAE(im_true, im_fake, data_range=255.):\n","    N = im_true.size()[0]\n","    C = im_true.size()[1]\n","    H = im_true.size()[2]\n","    W = im_true.size()[3]\n","    Itrue = im_true.clamp(0.,1.).mul_(data_range).reshape(N, C*H*W)\n","    Ifake = im_fake.clamp(0.,1.).mul_(data_range).reshape(N, C*H*W)\n","    mse = nn.MSELoss(reduce=False)\n","    err = mse(Itrue, Ifake).sqrt_().div_(Itrue).sum(dim=1, keepdim=True).div_(C*H*W)\n","    return torch.mean(err)\n","\n","def batch_RMSE(im_true, im_fake, data_range=255.):\n","    N = im_true.size()[0]\n","    C = im_true.size()[1]\n","    H = im_true.size()[2]\n","    W = im_true.size()[3]\n","    Itrue = im_true.clamp(0.,1.).mul_(data_range).reshape(N, C*H*W)\n","    Ifake = im_fake.clamp(0.,1.).mul_(data_range).reshape(N, C*H*W)\n","    mse = nn.MSELoss(reduce=False)\n","    err = mse(Itrue, Ifake).sum(dim=1, keepdim=True).div_(C*H*W).sqrt_()\n","    return torch.mean(err)\n","\n","def batch_SAM(im_true, im_fake):\n","    N = im_true.size()[0]\n","    C = im_true.size()[1]\n","    H = im_true.size()[2]\n","    W = im_true.size()[3]\n","    Itrue = im_true.clone().reshape(N, C, H*W)\n","    Ifake = im_fake.clone().reshape(N, C, H*W)\n","    nom = torch.mul(Itrue, Ifake).sum(dim=1).reshape(N, H*W)\n","    denom1 = torch.pow(Itrue,2).sum(dim=1).sqrt_().reshape(N, H*W)\n","    denom2 = torch.pow(Ifake,2).sum(dim=1).sqrt_().reshape(N, H*W)\n","    sam = torch.div(nom, torch.mul(denom1, denom2)).acos_().reshape(N, H*W)\n","    sam = sam / np.pi * 180\n","    sam = torch.sum(sam) / (N*H*W)\n","    return sam\n","\n","\n","def weights_init_kaimingNormal(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.kaiming_normal(m.weight.data, a=0.2, mode='fan_in')\n","    elif classname.find('Linear') != -1:\n","        nn.init.kaiming_normal(m.weight.data, a=0.2, mode='fan_in')\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal(m.weight.data, 0, 0.01)\n","        nn.init.constant(m.bias.data, 0.0)\n","    elif classname.find('InstanceNorm') != -1:\n","        nn.init.normal(m.weight.data, 0, 0.01)\n","        nn.init.constant(m.bias.data, 0.0)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9lERkS9S7Clt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tgeorKNY8BRa","colab_type":"code","colab":{}},"source":["#####             resblock\n","\n","def conv3x3(in_channels, out_channels):\n","    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n","                     stride=1, padding=1, bias=True)\n","    \n","class resblock(nn.Module):\n","    def __init__(self, block, block_num, input_channel, output_channel):\n","        super(resblock, self).__init__()\n","\n","        self.in_channels = input_channel\n","        self.out_channels = output_channel\n","        self.input_conv = conv3x3(self.in_channels, out_channels=64)  \n","        self.conv_seq = self.make_layer(block, block_num)\n","        self.conv = conv3x3(64, 64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.output_conv = conv3x3(in_channels=64,  out_channels=self.out_channels)\n","        \n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n=m.kernel_size[0]*m.kernel_size[1]*m.out_channels\n","                m.weight.data.normal_(0,sqrt(2./n))# the devide  2./n  carefully  \n","                \n","    def make_layer(self,block,num_layers):\n","        layers = []\n","        for i in range(num_layers):\n","            layers.append(block()) # there is a () \n","        return nn.Sequential(*layers)   \n","    \n","    def forward(self, x):\n","       \n","        out = self.input_conv(x)\n","        residual = out\n","        out = self.conv_seq(out)\n","        out = self.conv(out)\n","        out = torch.add(out,residual)  \n","        out = self.relu(out)\n","        out = self.output_conv(out)\n","        return out\n","\n","# Learning rate\n","def poly_lr_scheduler(optimizer, init_lr, epoch, lr_decay_iter=1,\n","                      max_iter=100, power=0.9):\n","    \"\"\"Polynomial decay of learning rate\n","        :param init_lr is base learning rate\n","        :param iter is a current iteration\n","        :param lr_decay_iter how frequently decay occurs, default is 1\n","        :param max_iter is number of maximum iterations\n","        :param power is a polymomial power\n","\n","    \"\"\"\n","    #if iteraion % lr_decay_iter or iteraion > max_iter:\n","    #    return optimizer\n","    rate = int(epoch / 100)\n","    lr = init_lr * np.power(0.9, rate)\n","    #lr = init_lr*(1 - iteraion/max_iter)**power\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","    return lr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lsjf6r6QcMQo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l6swvuIE-Lhm","colab_type":"code","colab":{}},"source":["## process the date\n","data_process(path=path) ## generate \"train_tomato.h5\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ERfixWWgWwjh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3xxBRKb6XVaO","colab_type":"code","colab":{}},"source":["\n","##                 the main training part (splitting data to trainng and testing)\n","#####   5 fold validation\n","for lt in loss_type:\n","    for f in range(5):\n","        iteration_folder = \"iteration_HSCNNR_{}_8_{}\".format(lt, str(f))\n","        model_folder = \"models_HSCNNR_{}_8_{}\".format(lt, str(f))\n","        #loss_type = \"mrae\" #\"mrae\"\n","        iteration_path = os.path.join(os.getcwd(), iteration_folder)\n","        if not os.path.exists(iteration_path):\n","            os.makedirs(iteration_path)\n","        ## new plot function with customed saving path\n","        \n","        def main():\n","            cudnn.benchmark = True\n","            ## network architecture\n","            rgb_features = 3\n","            hyper_features = 204\n","            ## load dataset\n","            print(\"\\nloading dataset ...\\n\")\n","            #\n","            trainDataset = HyperDataset(crop_size=30)  ## here not the training data but the whole data set for this work\n","            # set the ratio of training and validation set\n","            validation_split = (1/3)\n","            \n","            dataset_len = len(trainDataset) #trainDataset\n","            indices = list(range(dataset_len))\n","            \n","            # Randomly splitting indices:\n","            val_len = int(np.ceil(validation_split * dataset_len))\n","            validation_idx = np.random.choice(indices, size=val_len, replace=False)\n","            train_idx = list(set(indices) - set(validation_idx))\n","            \n","            ## Defining the samplers for each phase based on the random indices:\n","            train_sampler = SubsetRandomSampler(train_idx)\n","            validation_sampler = SubsetRandomSampler(validation_idx)\n","            \n","            # Data Loader (Input Pipeline)\n","            train_data_loader = DataLoader(dataset=trainDataset,\n","                                           sampler=train_sampler,\n","                                           num_workers=1,  \n","                                           batch_size=8,\n","                                           shuffle=False,\n","                                           pin_memory=True)\n","            \n","            val_loader = DataLoader(dataset=trainDataset,\n","                                    sampler=validation_sampler,\n","                                    num_workers=1, \n","                                    batch_size=1,\n","                                    shuffle=False,\n","                                   pin_memory=True)\n","            \n","            # Model               \n","            model = resblock(conv_relu_res_relu_block, 6, 3,204)\n","            # check whether it is possible to do multi-GPU processing\n","            if torch.cuda.device_count() > 1:\n","                model = nn.DataParallel(model)\n","            if torch.cuda.is_available():\n","                model.cuda()\n","          \n","            # Parameters, Loss and Optimizer\n","            start_epoch = 0\n","            end_epoch = 3000\n","            init_lr = 5e-3\n","            iteration = 0\n","            \n","            ## set the original values for the evaluation\n","            record_ts_loss = np.inf\n","            record_ts_MRAE = np.inf\n","            record_ts_RMSE = np.inf\n","            record_ts_SAM = np.inf\n","            # decide which loss function to use\n","            #criterion = nn.MSELoss()\n","            criterion = mrae_loss\n","            optimizer=torch.optim.Adamax(model.parameters(), lr=init_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4)\n","            \n","            model_path = os.path.join(os.getcwd(), model_folder)\n","            if not os.path.exists(model_path):\n","                os.makedirs(model_path)\n","            loss_csv = open(os.path.join(model_path, loss_type + '_loss_{}.csv'.format(str(f))), 'w+')\n","            \n","            log_dir = os.path.join(model_path,loss_type + '_train_{}.log'.format(str(f)))\n","            logger = initialize_logger(log_dir)\n","            \n","            # Resume\n","            resume_file =\"\" # can be specified if there is already trained model \n","            if resume_file:\n","                print(\"=> loading checkpoint '{}'\".format(resume_file))\n","                checkpoint = torch.load(os.path.join(model_path, resume_file))\n","                start_epoch = checkpoint['epoch']\n","                iteration = checkpoint['iter']\n","                model.load_state_dict(checkpoint['state_dict'])\n","                optimizer.load_state_dict(checkpoint['optimizer'])\n","               \n","            for epoch in range(start_epoch + 1, end_epoch): ## specify the number of epochs to run\n","                \n","                start_time = time.time()         \n","                tr_loss, tr_MRAE, tr_RMSE, tr_SAM, iteration, lr = train(train_data_loader, model, criterion, optimizer, iteration, init_lr, epoch)\n","                # here to implement constant learning rate\n","                end_time = time.time() # only record the training time\n","                epoch_time = end_time - start_time\n","                print(datetime.datetime.now())\n","                #lr=init_lr\n","                ts_loss, ts_MRAE, ts_RMSE,ts_SAM = validate(val_loader, model, criterion, epoch)\n","                \n","                # Save model\n","                # (1) ts_loss evaluation\n","                print(\"old_ts_MRAE\", record_ts_MRAE, \"old_ts_RMSE\",record_ts_RMSE, \"old_ts_SAM\",record_ts_SAM)\n","        \n","                if ts_MRAE < record_ts_MRAE:\n","                    record_ts_MRAE = ts_MRAE\n","                    save_checkpoint_sp(model_path, epoch, iteration, model, optimizer, \"ts_MRAE\")\n","                    print(\"ts_MRAE\")\n","                    print(\"updated_ts_MRAE\", record_ts_MRAE, \"updated_ts_RMSE\",record_ts_RMSE, \"updated_ts_SAM\",record_ts_SAM)\n","        \n","                if ts_RMSE < record_ts_RMSE:  \n","                    record_ts_RMSE = ts_RMSE\n","                    save_checkpoint_sp(model_path, epoch, iteration, model, optimizer, \"ts_RMSE\")\n","                    print(\"ts_RMSE\")\n","                    print(\"updated_ts_MRAE\", record_ts_MRAE, \"updated_ts_RMSE\",record_ts_RMSE, \"updated_ts_SAM\",record_ts_SAM)\n","        \n","                if ts_SAM < record_ts_SAM:\n","                    record_ts_SAM = ts_SAM\n","                    save_checkpoint_sp(model_path, epoch, iteration, model, optimizer, \"ts_SAM\")\n","                    print(\"ts_SAM\")\n","                    #print(\"                                  updated_min_val_RMSE\",record_test_loss)\n","                    print(\"updated_ts_MRAE\", record_ts_MRAE, \"updated_ts_RMSE\",record_ts_RMSE, \"updated_ts_SAM\",record_ts_SAM)\n","                    \n","                print(\"\")\n","                # print loss \n","        \n","                print (\"fold: {}, Epoch:{}, Iter:{}, Time:{}, learning rate:{}, Train MRAE:{}, Train RMSE:{}, Train SAM:{}\".format(\n","                    f, epoch, iteration, epoch_time, lr, tr_MRAE,tr_RMSE, tr_SAM))\n","                print (\"Test MRAE:{}, Test RMSE:{}, Test SAM:{}\".format(ts_MRAE, ts_RMSE, ts_SAM))\n","                # save loss( the content of \"record loss\" function is here)\n","                loss_csv.write('{},{},{},{},{},{},{},{},{},{},{}\\n'.format(f, epoch, iteration, epoch_time, lr, tr_MRAE, tr_RMSE,\n","                                                                                                 tr_SAM, ts_MRAE, ts_RMSE, ts_SAM))\n","                loss_csv.flush()    \n","                loss_csv.close\n","                #record_loss_sp(loss_csv,epoch, iteration, epoch_time, lr, tr_loss,tr_MRAE, tr_RMSE_1,\n","                #                                                    tr_rRMSE_1, tr_RMSE_2,tr_rRMSE_2, tr_SAM, ts_loss, ts_MRAE,\n","                #                                                    ts_RMSE_1,ts_rRMSE_1,ts_RMSE_2,ts_rRMSE_2,ts_SAM)     \n","                logger.info(\"fold{},Epoch{}, Iter{}, Time:{}, learning rate:{}, Train MRAE:{},Train RMSE:{}, Train SAM:{}, Test MRAE:{},Test RMSE:{}, Test SAM:{}\".format(\n","                    f, epoch, iteration, epoch_time, lr, tr_MRAE,tr_RMSE, tr_SAM, ts_MRAE,ts_RMSE,ts_SAM))\n","        \n","    # Training \n","    def train(train_data_loader, model, criterion, optimizer, iteration, init_lr ,epoch):\n","        \n","        losses = AverageMeter()\n","        \n","        average_MRAE = 0.\n","        average_RMSE = 0. \n","        average_SAM = 0.\n","    \n","        num=len(train_data_loader)\n","        print('num.{}'.format(num))\n","        optimizer.zero_grad()\n","    \n","        for i, (labels, images) in enumerate(train_data_loader):\n","            H = labels.size(2)\n","            W = labels.size(3)\n","            #\n","            labels = labels.cuda(async=True)\n","            images = images.cuda(async=True)\n","            #\n","            images = Variable(images)\n","            labels = Variable(labels)    \n","            \n","            # Decaying Learning Rate\n","            lr = poly_lr_scheduler(optimizer, init_lr, epoch, max_iter=968000, power=1.5) \n","            iteration = iteration + 1\n","            #       \n","            output = model.forward(images)\n","            loss = criterion(labels, output)\n","            loss.backward()\n","            ## accumulate the loss for more than one batchs if necessary\n","            if (i+1)%1==0: # sepcify how many batches to accumulate the gradients\n","                #print(\"accumulated\", j+1)\n","                optimizer.step()\n","                optimizer.zero_grad()\n","            #####\n","            MRAE = batch_MRAE(labels, output)\n","            RMSE = batch_RMSE(labels, output)\n","            SAM = batch_SAM(labels, output)\n","            \n","            average_MRAE    += MRAE.item()\n","            average_RMSE    += RMSE.item()\n","            average_SAM    += SAM.item()\n","        \n","        return losses.avg, average_MRAE/num, average_RMSE/num, average_SAM/num, iteration, lr\n","    \n","    # Validation\n","    \n","    def validate(val_loader, model, criterion, epoch):\n","            \n","        model.eval()\n","        losses = AverageMeter()\n","        xxx=0\n","        num = len(val_loader)\n","    \n","        average_MRAE    =0.\n","        average_RMSE    =0.\n","        average_SAM    =0.\n","    \n","        #v_accu= 0.\n","        for i, (target, input) in enumerate(val_loader):\n","            #\n","            H = target.size(2)\n","            W = target.size(3)\n","            #\n","            input = input.cuda(async=True)\n","            target = target.cuda(async=True)\n","            input_var = torch.autograd.Variable(input)\n","            target_var = torch.autograd.Variable(target)\n","    \n","            # compute output\n","            with torch.no_grad():\n","                output = model.forward(input_var)\n","            loss = criterion(output, target_var)\n","            #####\n","            MRAE = batch_MRAE(target_var, output)\n","            RMSE = batch_RMSE(target_var, output)\n","            SAM = batch_SAM(target_var, output)\n","            \n","            average_MRAE    += MRAE.item()\n","            average_RMSE    += RMSE.item()\n","            average_SAM    += SAM.item()\n","            #####\n","            ## generate a figure compare the reconstructed spectra and ground truth, every epoch\n","            if epoch%1==0:\n","                #print(i)\n","                if (i+2)%3==0:\n","                    xxx += 1\n","                    real_spectrum = target_var.data.cpu().numpy()[0,:,int(H/2),int(W/2)]\n","                    fake_spectrum = output.data.cpu().numpy()[0,:,int(H/2),int(W/2)]\n","                    I_spectrum = plot_spectrum(real_spectrum, fake_spectrum, \"val_\"+str(epoch),i)\n","                    print(\"val_num: \" + str(xxx))\n","            #  record loss\n","            losses.update(loss.item())\n","        return losses.avg, average_MRAE/num, average_RMSE/num, average_SAM/num\n","    \n","    if __name__ == '__main__':\n","        main()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MuDVvSAnCdc6","colab_type":"code","colab":{}},"source":["#"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJhhV1NGWjpL","colab_type":"code","colab":{}},"source":["## here is to close the already open csv file in case the running process was stopped in the middle\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","import os\n","loss_csv.close\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9lOTEeerQqtN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOGRUSPvQq6u","colab_type":"code","colab":{}},"source":["## reconstruct hyperspectral images from smartphone RGB images in a loop\n","\n","def get_reconstruction(input, num_split, dimension, model):\n","    \"\"\"As the limited GPU memory split the input.\"\"\"\n","    input_split = torch.split(input,  int(input.shape[3]/num_split), dim=dimension)\n","    output_split = []\n","    for i in range(num_split):\n","        var_input = Variable(input_split[i].cuda())\n","        var_output = model(var_input)\n","        output_split.append(var_output.data)\n","        if i == 0:\n","            output = output_split[i]\n","        else:\n","            output = torch.cat((output, output_split[i]), dim=dimension)\n","    return output\n","\n","def reconstruction(rgb,model):\n","    \"\"\"Output the final reconstructed hyperspectral images.\"\"\"\n","    img_res = get_reconstruction(torch.from_numpy(rgb).float(),1, 3, model)\n","    img_res = img_res.cpu().numpy()*1\n","    img_res = np.transpose(np.squeeze(img_res))\n","    img_res_limits = np.minimum(img_res,1)\n","    img_res_limits = np.maximum(img_res_limits,0)\n","    return img_res_limits\n","\n","######  \n","loss_type = [\"mrae\", \"mse\"]\n","\n","for lt in loss_type:\n","    for i in range(5):\n","        iter_folder_rc = \"SMt_iteration_HSCNNR_{}_8_{}\".format(lt, str(i))  ## specify which folder to use\n","        loss_type = \"{}_\".format(lt) # specify the loss type \n","        iter_path = os.path.join(os.getcwd(),iter_folder_rc)\n","        if not os.path.exists(iter_path):\n","            os.makedirs(iter_path)\n","        ##\n","        model_folder = \"models_HSCNNR_{}_8_{}\".format(lt,str(i))\n","        input_path = os.path.join(os.getcwd(), model_folder)\n","        if not os.path.exists(input_path):\n","            os.makedirs(input_path)\n","        ##\n","        out_folder = \"SMt_out_HSCNNR_{}_8_{}\".format(lt,str(i))\n","        out_path= os.path.join(os.getcwd(), out_folder)\n","        if not os.path.exists(out_path):\n","            os.makedirs(out_path)\n","        \n","        ## the model names\n","        loss_csv = open(os.path.join(out_path, loss_type + 'evaluation.csv'), 'w+')\n","        \n","        models_ids = [f for f in os.listdir(input_path) if f.endswith('.pkl')]\n","        \n","        for i in range(len(models_ids)):\n","            models_ids_i = models_ids[i] # the ith model name\n","            models_path = input_path\n","            models_path_i = os.path.join(models_path, models_ids_i)\n","            ## subtract the folder name\n","            eval_rc_i = \"_\".join(models_ids_i.split(\".\")[0].split(\"_\")[4:])\n","            models_path_out_i = os.path.join(out_path, loss_type + eval_rc_i)\n","            \n","            if not os.path.exists(models_path_out_i):\n","                os.makedirs(models_path_out_i) \n","            #read the model\n","            var_name = 'img' # the variable name used in mat file\n","            # load the weights\n","            save_point = torch.load(models_path_i)\n","            model_param = save_point['state_dict']\n","            model = resblock(conv_relu_res_relu_block,6,3,204)\n","            model.load_state_dict(model_param)\n","            model = model.cuda()\n","            model.eval()\n","            ## Reconstruct HSI of all test images\n","        \n","            #  load the images\n","            img_path = \"input image folder path\"\n","        \n","            png_files= [f for f in os.listdir(img_path) if f.endswith('.png')]\n","            \n","            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","            \n","            for img_name in sorted(png_files):\n","                print ((\"img_name\",img_name))\n","                hyper_name = img_name.replace(\"png\", \"h5\")\n","                \n","                img_path_name = os.path.join(img_path, img_name)\n","                rgb = cv2.imread(img_path_name)\n","                rgb = cv2.rotate(rgb, cv2.ROTATE_90_CLOCKWISE)\n","                rgb=cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n","                \n","                H = rgb.shape[0]\n","                W = rgb.shape[1]\n","        \n","                rgb = normalize(np.float32(rgb))\n","                print((\"rgb_or\", rgb.shape))\n","                rgb = np.expand_dims(np.transpose(rgb,[2,0,1]), axis=0).copy()\n","                print((\"rgb_ex\", rgb.shape)) \n","                ##\n","                \n","                #img_res1 = reconstruction(rgb,model)\n","                img_res = get_reconstruction(torch.from_numpy(rgb).float(),1, 3, model)\n","        \n","                # prepare to save the reconstructed HSI\n","                print((\"img_res\", img_res.shape))\n","                img_res_n = img_res.cpu().numpy()*1\n","                img_res_n = np.transpose(np.squeeze(img_res_n))\n","                # clip the data to 0 and 1 range\n","                img_res_n_limits = np.minimum(img_res_n,1)\n","                img_res_n_limits = np.maximum(img_res_n_limits,0)\n","        \n","                print((\"img_res_n\", img_res_n_limits.shape))\n","                # create the file name for .mat file\n","                mat_name = img_name.split(\".\")[0] + '.mat'\n","                print((\"mat_name\",mat_name))\n","        \n","                mat_dir= os.path.join(models_path_out_i, mat_name)\n","                print(mat_dir)\n","                save_matv73(mat_dir, var_name, img_res_n_limits)\n","         "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VwhKynPTQq4L","colab_type":"code","colab":{}},"source":["\n","##       using the trained model to reconstruct \"redness image\" from SMARTPHONE images\n","\n","def get_reconstruction(input, num_split, dimension, model):\n","    \"\"\"As the limited GPU memory split the input.\"\"\"\n","    input_split = torch.split(input,  int(input.shape[3]/num_split), dim=dimension)\n","    output_split = []\n","    for i in range(num_split):\n","        var_input = Variable(input_split[i].cuda())\n","        var_output = model(var_input)\n","        output_split.append(var_output.data)\n","        if i == 0:\n","            output = output_split[i]\n","        else:\n","            output = torch.cat((output, output_split[i]), dim=dimension)\n","    \n","    return output\n","\n","def reconstruction(rgb,model):\n","    \"\"\"Output the final reconstructed hyperspectral images.\"\"\"\n","    img_res = get_reconstruction(torch.from_numpy(rgb).float(),1, 3, model)\n","    img_res = img_res.cpu().numpy()*1\n","    img_res = np.transpose(np.squeeze(img_res))\n","    img_res_limits = np.minimum(img_res,1)\n","    img_res_limits = np.maximum(img_res_limits,0)\n","    return img_res_limits\n","\n","\n","## specify the model folder\n","#mse_models_path = glob.glob(os.path.join(os.getcwd(), mse_model_folder, '*.pkl'))\n","mse_models_path = \"model path\"\n","\n","var_name = 'img' ## specify the variable name of the .mat file\n","# load the model weights\n","save_point = torch.load(mse_models_path)\n","model_param = save_point['state_dict']\n","model = resblock(conv_relu_res_relu_block,6,3,204)\n","model.load_state_dict(model_param)\n","\n","model = model.cuda()\n","model.eval()\n","\n","## Reconstruct HSI of all test images\n","\n","img_path = 'input_path' # path of smartphone image\n","result_path = 'output_path' # path of reconstructed HSI of smartphone image\n","if not os.path.exists(result_path):\n","    os.makedirs(result_path)\n","\n","png_files= [f for f in os.listdir(img_path) if f.endswith('.png')]\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","num = len(png_files)\n","\n","for img_name in sorted(png_files):\n","    print ((\"img_name\",img_name))\n","    hyper_name = img_name.replace(\"png\", \"h5\")\n","\n","    img_path_name = os.path.join(img_path, img_name)\n","    rgb = cv2.imread(img_path_name)\n","    rgb=cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n","    if rgb.shape[0]<rgb.shape[1]:\n","        rgb =  cv2.rotate(rgb, cv2.ROTATE_90_CLOCKWISE)\n","\n","    rgb= cv2.resize(rgb, (512, 512)) # for change the resolution to fit the RAM of your computer\n","\n","    H = rgb.shape[0] \n","    W = rgb.shape[1] \n","\n","    rgb = normalize(np.float32(rgb))\n","    print((\"rgb_or\", rgb.shape))\n","    ## specify the placeholder for output image     \n","    rgb_i = np.expand_dims(np.transpose(rgb,[2,0,1]), axis=0).copy()\n","    print((\"rgb_ex\", rgb_i.shape)) \n","    #img_res1 = reconstruction(rgb,model)\n","    img_res_i = get_reconstruction(torch.from_numpy(rgb_i).float(),1, 3, model)\n","\n","    # prepare to save the reconstructed HSI\n","    print((\"img_res\", img_res_i.shape))\n","    img_res_i_n = img_res_i.cpu().numpy()*1\n","    print((\"img_res_i_n\", img_res_i_n.shape ))\n","    img_res_i_n = np.squeeze(img_res_i_n)\n","    # calculate redness of each pixel\n","    img_res_i_n_800 = img_res_i_n[137,:,:] # 800 nm \n","    img_res_i_n_680 = img_res_i_n[97,:,:]  # 680 nm\n","    img_res_i_n_x = 1-np.abs((img_res_i_n_800 - img_res_i_n_680)/(img_res_i_n_800 + img_res_i_n_680))\n","\n","    img_res_i_n_x = np.transpose(img_res_i_n_x,[1,0])\n","    print((\"img_res_i_n_reshape\", img_res_i_n_x.shape ))\n","    img_res_i_n_x_limits = np.minimum(img_res_i_n_x,1)\n","    img_res_i_n_x_limits = np.maximum(img_res_i_n_x,0)\n","    print((\"img_res_i_n\", img_res_i_n_x_limits.shape))\n","    \n","    mat_name = img_name.split(\".\")[0] + '.mat'\n","    print((\"mat_name\",mat_name))\n","    mat_dir= os.path.join(result_path, mat_name)\n","    print(mat_dir)\n","    save_matv73(mat_dir, var_name, img_res_i_n_x_limits)\n","    #print(\"file_name\", file_name)  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yiJ3fM0FQq9U","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Git5L9FQrAb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}